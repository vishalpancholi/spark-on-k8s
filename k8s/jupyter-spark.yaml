apiVersion: v1
kind: Pod
metadata:
  name: jupyter-spark
  namespace: spark
  labels:
    app: jupyter-spark
spec:
  serviceAccountName: spark-driver
  containers:
    - name: jupyter-spark
      image: vishalpancholi/spark-delta:v1
      command: ["/bin/bash"]
      args:
        - "-c"
        - |
          # Install Jupyter as this is not in image
          pip install jupyter jupyterlab
          
          # Set up Jupyter configuration
          jupyter lab --generate-config
          
          # Create Jupyter config for remote access
          cat > /root/.jupyter/jupyter_lab_config.py << 'EOF'
          c.ServerApp.ip = '0.0.0.0'
          c.ServerApp.port = 8888
          c.ServerApp.open_browser = False
          c.ServerApp.allow_root = True
          c.ServerApp.token = 'spark-jupyter-token'
          c.ServerApp.password = ''
          EOF
          
          # Start Jupyter Lab
          cd /opt/spark/work-dir
          jupyter lab

      env:
        # Spark configuration
        - name: SPARK_MASTER_URL
          value: "k8s://https://kubernetes.default.svc.cluster.local:443"
        - name: SPARK_KUBERNETES_CONTAINER_IMAGE
          value: "vishalpancholi/spark-delta:v1"

        # Hive Metastore configuration
        - name: HIVE_METASTORE_JDBC_URL
          valueFrom:
            secretKeyRef:
              name: mysql-credentials
              key: jdbc-url
        - name: HIVE_METASTORE_USER
          valueFrom:
            secretKeyRef:
              name: mysql-credentials
              key: username
        - name: HIVE_METASTORE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-credentials
              key: password

        # Azure Storage Account
        - name: AZURE_STORAGE_ACCOUNT
          value: "granicasa"

      ports:
        - containerPort: 8888
          name: jupyter-port
        - containerPort: 4040
          name: spark-ui

      volumeMounts:
        - name: spark-config
          mountPath: /opt/spark/conf/spark-defaults.conf
          subPath: spark-defaults.conf

      resources:
        requests:
          memory: "2Gi"
          cpu: "500m"
        limits:
          memory: "3Gi"
          cpu: "1"

  volumes:
    - name: spark-config
      configMap:
        name: spark-config

  restartPolicy: Always
---
# Service to access Jupyter
apiVersion: v1
kind: Service
metadata:
  name: jupyter-spark-service
  namespace: spark
spec:
  selector:
    app: jupyter-spark
  ports:
    - name: jupyter
      port: 8888
      targetPort: 8888
    - name: spark-ui
      port: 4040
      targetPort: 4040
  type: ClusterIP