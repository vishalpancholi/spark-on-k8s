apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-config
  namespace: spark
data:
  spark-defaults.conf: |
    # DELTA LAKE
    spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
    spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog

    # KUBERNETES
    spark.kubernetes.authenticate.driver.serviceAccountName=spark-driver
    spark.kubernetes.namespace=spark
    spark.kubernetes.executor.deleteOnTermination=true
    spark.kubernetes.driver.deleteOnTermination=true
    spark.kubernetes.container.image=vishalpancholi/spark-delta:v15
    
    # DYNAMIC PARTITIONING
    spark.sql.sources.partitionOverwriteMode=dynamic
    spark.sql.catalogImplementation=hive    
    
    # RESOURCE ALLOCATION
    spark.executor.instances=3
    spark.driver.memory=1500m
    spark.driver.cores=1
    spark.executor.memory=1500m
    spark.executor.cores=1

    # spark AQE optimization
    spark.sql.adaptive.enabled=true
    spark.sql.adaptive.coalescePartitions.enabled=true
    spark.sql.adaptive.skewJoin.enabled=true
    spark.sql.shuffle.partitions=10
    
    # AZURE STORAGE (Access key)
    spark.hadoop.fs.azure.account.key.granicasa.dfs.core.windows.net=${STORAGE_ACCESS_KEY}

    # SPARK EVENT LOGS location
    spark.eventLog.enabled=true
    spark.eventLog.dir=abfss://mycontainer@granicasa.dfs.core.windows.net/spark-events

    # KUBERNETES MASTER
    spark.master=k8s://https://kubernetes.default.svc
    
    spark.hadoop.javax.jdo.option.ConnectionURL=jdbc:mysql://spark-hms-mysql-server.mysql.database.azure.com:3306/hive_metastore
    spark.hadoop.javax.jdo.option.ConnectionDriverName=com.mysql.cj.jdbc.Driver
    spark.hadoop.javax.jdo.option.ConnectionUserName=mysqladmin
    spark.hadoop.javax.jdo.option.ConnectionPassword=${HIVE_METASTORE_PASSWORD}
    
    # PROMETHEUS METRICS CONFIGURATION
    spark.ui.prometheus.enabled=true
    spark.metrics.namespace=spark
    spark.metrics.conf.driver.sink.prometheusServlet.class=org.apache.spark.metrics.sink.PrometheusServlet
    spark.metrics.conf.driver.sink.prometheusServlet.path=/metrics/driver
    spark.metrics.conf.executor.sink.prometheusServlet.class=org.apache.spark.metrics.sink.PrometheusServlet
    spark.metrics.conf.executor.sink.prometheusServlet.path=/metrics/executors
    
    # Enable JMX metrics (optional but useful)
    spark.metrics.conf.*.sink.jmx.class=org.apache.spark.metrics.sink.JmxSink
    
    # PROMETHEUS ANNOTATIONS (for PodMonitor autodiscovery)
    spark.kubernetes.driver.annotation.prometheus.io/scrape=true
    spark.kubernetes.driver.annotation.prometheus.io/port=4040
    spark.kubernetes.driver.annotation.prometheus.io/path=/metrics/driver
    spark.kubernetes.executor.annotation.prometheus.io/scrape=true
    spark.kubernetes.executor.annotation.prometheus.io/port=4041
    spark.kubernetes.executor.annotation.prometheus.io/path=/metrics/executors
