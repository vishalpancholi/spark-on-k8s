apiVersion: v1
kind: Pod
metadata:
  name: spark-shell
  namespace: spark
  labels:
    app: spark-shell
spec:
  serviceAccountName: spark-driver
  containers:
    - name: spark-shell
      image: vishalpancholi/spark-delta:v1
      command: ["/bin/bash"]
      args: ["-c", "while true; do sleep 30; done"]
      env:
        # Spark configuration
        - name: SPARK_MASTER_URL
          value: "k8s://https://kubernetes.default.svc.cluster.local:443"
        - name: SPARK_KUBERNETES_CONTAINER_IMAGE
          value: "vishalpancholi/spark-delta:v1"

        # Hive Metastore configuration (using Docker image's hive-site.xml)
        - name: HIVE_METASTORE_JDBC_URL
          valueFrom:
            secretKeyRef:
              name: mysql-credentials
              key: jdbc-url
        - name: HIVE_METASTORE_USER
          valueFrom:
            secretKeyRef:
              name: mysql-credentials
              key: username
        - name: HIVE_METASTORE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-credentials
              key: password

        # Azure Storage Account (replace with your account name)
        - name: AZURE_STORAGE_ACCOUNT
          value: "yourstorageaccount"

      volumeMounts:
        # Only mount Spark configuration - Hive config is in your Docker image
        - name: spark-config
          mountPath: /opt/spark/conf/spark-defaults.conf
          subPath: spark-defaults.conf

      resources:
        requests:
          memory: "2.5Gi"
          cpu: "1"
        limits:
          memory: "3Gi"
          cpu: "1.5"

  volumes:
    - name: spark-config
      configMap:
        name: spark-config

  restartPolicy: Always